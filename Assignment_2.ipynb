{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9 August 2023**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><b>Task 1</b></center></h3>\n",
    "\n",
    "- Create a folder : Imagedata ( as informed in session )\n",
    "- Add three folders training, validation and testing\n",
    "- Add two folders laptop and mobile in training and validation folders\n",
    "- Add images in all 4 folders ( respective images laptop / mobile )\n",
    "- Try to develop a Convolutional Neural Network (CNN) which could predict the images from the testing folder. (whether it is mobile or laptop)\n",
    "\n",
    "- <b>Note :</b> Neural Network is a part of deep learning which is very much higher concept of Data Science, Student can take reference from internet or any available project over internet. No need to understand this mathematically. This task is optional, designed for understanding and vision only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 1: Folder Structure</b>\n",
    "\n",
    "- Create the following folder structure:\n",
    "\n",
    "Imagedata:\n",
    "1. training  --> laptop & mobile\n",
    "2. validation  --> laptop & mobile\n",
    "3. testing  --> laptop & mobile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 2: Loading and Preprocessing Data</b>\n",
    "\n",
    "- Load and preprocess the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 100 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Specify the paths\n",
    "train_data_dir = 'Imagedata/training'\n",
    "validation_data_dir = 'Imagedata/validation'\n",
    "test_data_dir = 'Imagedata/testing'\n",
    "\n",
    "# Set up data generators with data augmentation for training and validation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(150, 150),  # Resize images to the desired dimensions\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Since we have two classes: laptop and mobile\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 3: Building the CNN Model</b>\n",
    "- Creation of a simple CNN model using Keras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    MaxPooling2D(2, 2),\n",
    "    Flatten(),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Using sigmoid for binary classification\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 4: Training the Model</b>\n",
    "- Train the model using the prepared generators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2/3 [===================>..........] - ETA: 0s - loss: 0.7175 - accuracy: 0.5833"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 5s 1s/step - loss: 1.1919 - accuracy: 0.5588 - val_loss: 0.8416 - val_accuracy: 0.5208\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 3s 1s/step - loss: 0.6472 - accuracy: 0.6618 - val_loss: 1.4237 - val_accuracy: 0.5104\n",
      "Epoch 3/10\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Step 5: Evaluating the Model</b>\n",
    "- After training, evaluate the model's performance on the testing data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 2s 739ms/step - loss: 0.6871 - accuracy: 0.5104\n",
      "Test accuracy: 0.5104166865348816\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3><center><b>Task 2: OPEN CV</b></center></h3>\n",
    "\n",
    "- Write script to Open Camera.\n",
    "- Write script to Open Camera in gray scale mode ( black and white )\n",
    "- Write script to Capture image on click of key “c” while camera is open. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>1. Open Camera:</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the camera\n",
    "    cv2.imshow('Camera', frame)  # Display the frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the camera\n",
    "cv2.destroyAllWindows()  # Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>2. Open Camera in Gray Scale Mode (Black & White):</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the camera\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to gray scale\n",
    "    cv2.imshow('Gray Scale Camera', gray_frame)  # Display the gray scale frame\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the camera\n",
    "cv2.destroyAllWindows()  # Close all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>3. Capture Image on Key \"c\":</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image captured!\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "# Open the default camera (camera index 0)\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()  # Read a frame from the camera\n",
    "    cv2.imshow('Camera', frame)  # Display the frame\n",
    "    \n",
    "    key = cv2.waitKey(1)\n",
    "    if key & 0xFF == ord('c'):  # Press 'c' to capture image\n",
    "        cv2.imwrite('captured_image.jpg', frame)  # Save the captured image\n",
    "        print(\"Image captured!\")\n",
    "\n",
    "    if key & 0xFF == ord('q'):  # Press 'q' to exit\n",
    "        break\n",
    "\n",
    "cap.release()  # Release the camera\n",
    "cv2.destroyAllWindows()  # Close all windows"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
